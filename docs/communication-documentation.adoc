= Team Contributions Summary
:toc:
:sectnums:

== Alexa M. Zaragoza Torres (alexamzt)
=== #101: Communication and the Use of Language: Modeling Out Loud for Swipe Flow
*Status:* Closed | *Urgency:* 5 | *Difficulty:* 4  

This issue required creating a comprehensive documentation of the swipe-to-chat flow by applying the principle of "modeling out loud"—a technique where complex domain interactions are explained through detailed, step-by-step narration that makes implicit assumptions explicit. This task went beyond creating simple flowchart diagrams; it demanded tracing the entire user journey from the moment a user initiates a swipe action through the creation of a reciprocal match and ultimately the enablement of a one-to-one chat conversation between matched parties.

The first critical component involved identifying all actors in the flow. This included not just the end users (Candidate and Recruiter) but also the various system components that orchestrate the interaction: the Profile service (which manages user data and visibility), the Swipe service (which records and evaluates user preferences), the Matching service (which determines if a reciprocal match exists), the Chat service (which enables messaging), and the Notification service (which alerts users to important events). Understanding each actor's role and responsibilities was essential for clarifying what each component contributes to the overall flow.

Equally important was establishing the preconditions that must be met before the flow can execute. These preconditions act as guards, preventing the system from attempting a flow that cannot possibly succeed. Specifically, users must be authenticated and signed in (an unauthenticated user cannot perform actions), their profiles must be visible to the discovery feed (otherwise there would be no profile to swipe on), and recommended profiles must be available to display (the system needs something to show the user). By making these preconditions explicit, the documentation prevents overlooking essential setup work.

The core intellectual contribution was articulating the domain rules that govern the entire flow's behavior. The reciprocity rule states that both parties must independently swipe right to create a match—a single-directional "like" doesn't create a connection until both show interest. The uniqueness rule ensures that only one active match can exist between any given user pair, preventing duplicate matching. The chat restriction rule explicitly forbids messaging before a match is confirmed, protecting user privacy and preventing unsolicited contact. Notifications must include retry logic for reliability because network failures are inevitable in distributed systems. Users must retain the ability to unmatch or report problematic connections, ensuring the system remains safe and respectful. Finally, all operations must be idempotent—re-running the same operation should produce identical results whether executed once or multiple times, which is essential for reliability when network failures cause retries.

Success required that this flow be traceable back through the requirements hierarchy to user stories, epics, and features, ensuring alignment between implementation details and business goals. All rules had to be explicitly captured and testable, not buried in implementation details. End-to-end validation had to occur across the entire sequence (swipe → match → chat → notification), not just individual steps. Finally, the documentation had to be approved by stakeholders and designated reviewers, ensuring it met expectations and represented shared understanding.


=== #226: Discovery Journal
*Status:* Closed | *Urgency:* 4 | *Difficulty:* 3  

This issue tasked the team with establishing a systematic mechanism for capturing and preserving domain insights that emerge during development sessions—the moments when developers encounter code or requirements that reveal something new about the business domain. Rather than allowing these valuable discoveries to be lost in pull request comments, commit messages, or team chat discussions that would eventually scroll out of view, a Discovery Journal creates a permanent, searchable record of learning that the entire team can reference.

The journal's purpose extends beyond documentation for documentation's sake. By capturing discoveries systematically, the team creates institutional memory that survives personnel changes and prevents re-learning the same lessons multiple times. When a developer discovers that a particular business rule had hidden complexity, or that two apparently separate concepts should actually be unified, or that the previous understanding of customer needs was incomplete—these insights deserve to be preserved in a form that makes them discoverable and meaningful to the next person who encounters the same domain.

The discovery journal established a consistent entry format that captures the full context of each discovery: the problem or situation that triggered the insight (the "why were we thinking about this?"), the domain insight itself (the new understanding or mental model shift), the change applied to address it (how did we modify our code or understanding in response?), and the business impact (why does this matter to our users or our project?). Each entry includes metadata—the date and ideally a link to the related commit or pull request so team members could trace from the discovery back to the actual code change and see it in context.

A critical requirement was that entries use ubiquitous language—the shared vocabulary defined in the domain glossary and bounded contexts. This prevents terminology drift where different team members might use different words for the same concept, making it harder to find related discoveries and creating confusion. When the entire team speaks the same language, the journal becomes much more valuable as a learning resource.

Success required at least five dated entries, demonstrating that the journal would actually be used and maintained, not abandoned after a single entry. At least three entries had to link to real commits or pull requests, proving that discoveries were being captured as they happened during actual development rather than being reconstructed later from memory. Each entry had to connect the technical change to a concrete business concept (such as an eligibility rule or decision calendar logic), not just describe low-level code changes. This emphasis on business meaning ensures the journal serves learning purposes across the entire team, not just for developers.


=== #121: Knowledge Crunching for Recruiter Needs
*Status:* Closed | *Urgency:* 6 | *Difficulty:* 5  

This issue required conducting primary research to deeply understand what recruiters actually need from messaging and notifications features. "Knowledge crunching" refers to the intensive process of interviewing domain experts, synthesizing their responses into structured insights, and distilling those insights into implementable requirements. Rather than making assumptions about recruiter needs, this issue mandated direct engagement with actual practitioners or credible proxies.

The work began with creating a structured interview guide containing 10–12 carefully crafted prompts designed to explore recruiter pain points around chat and notifications without introducing interviewer bias. Questions explored which filters or search criteria recruiters need to efficiently find relevant candidates, what types of alerts trigger action (new applicant, match confirmation, interview reminder), when recruiters prefer to receive notifications (during work hours only, or any time), whether read receipts (seeing when the recipient has viewed a message) mattered to their workflow, how they wanted to receive interview invitations and reminders, and how they preferred to handle follow-ups with candidates.

The research required scheduling and conducting at least two interviews with practicing recruiters or credible proxies (such as career services directors who work closely with recruiters). If live interviews weren't feasible, the alternative was conducting desk research by analyzing at least three authoritative published sources about recruiter workflows. During sessions, notes were taken and direct quotes were anonymized to respect participant confidentiality.

The synthesis phase involved identifying the top recruiter needs and pain points using jobs-to-be-done analysis—a framework that focuses on what specific job the recruiter is trying to accomplish (e.g., "identify qualified candidates quickly" is a job to be done) rather than starting from solution assumptions. This reframing helps identify the real underlying needs rather than just the solutions recruiters think they want.

A critical deliverable was an event matrix documenting each type of communication event (new message, new match, interview invite, interview reminder, follow-up request), the audience for that event (which recruiters receive it), the preferred channel (push notification, in-app alert, email), the priority level (urgent, normal, low), and the deep link target in the app where the recruiter should be taken when they tap the notification. This level of detail ensures the implementation would be specifically tailored to recruiter workflows rather than generic.

The final deliverable included a prioritized list of 5–7 requirements using the MoSCoW framework (Must have: absolutely essential, Should have: important but not blocking, Could have: nice to have, Won't have: deliberately excluded). All requirements had to be ready for implementation in the next sprint, not abstract wishes. Success required formal approval from stakeholders, indicating that the research met quality standards and captured requirements the team felt confident implementing.


=== #119: Research: Enabling Seamless Notifications in Flutter (Supabase Integration)
*Status:* Closed | *Urgency:* 6 | *Difficulty:* 5  

This issue required conducting comprehensive research to enable informed decision-making about implementing real-time push and in-app notifications using Flutter (the mobile development framework) and Supabase (the backend platform). The research was explicitly scoped as investigation only—no production code would be written, but all findings would be immediately actionable for implementation planning.

The research packet needed to cover core notification events that the system must support. At minimum this included new message notifications (when a matched user sends a message) and new match notifications (when both users have indicated mutual interest). For each event type, the research documented the target audience (which users receive this notification), the content that should appear (what text, which user data should be included), and the deep link targets (where in the app should the user be taken when they tap the notification to see the full context).

A critical component was the Flutter SDKs quick check—researching which packages and libraries exist for notifications, what capabilities each provides, what setup effort each requires, and what trade-offs exist between them. This research informed technology selection decisions that would have long-term implications for maintenance and performance.

Platform-specific setup was thoroughly documented because Android and iOS differ significantly in notification handling. For Android, the research covered required permissions (like POST_NOTIFICATIONS for Android 13+), notification channel configuration (how to categorize and group notifications), and considerations for app behavior when running in the background (Android restricts background execution to preserve battery). For iOS, the research covered APNs (Apple Push Notification service) certificate and key requirements, capability configuration in Xcode, and the significant limitation that push notifications cannot be reliably tested on the iOS simulator (requiring physical device testing).

The data and security section identified which backend tables are necessary to store device tokens and notification preferences, how to protect sensitive data like tokens from unauthorized access, and the lifecycle for managing tokens (adding new ones when users install the app, updating them when tokens expire, deleting them when users uninstall or revoke permissions).

Critically, the research identified the top three technical risks (such as tokens becoming stale and unable to receive notifications, delivery failures when push services are temporarily unavailable, or data leaks if tokens are exposed to unauthorized parties) and for each risk proposed concrete mitigations. The research packet included a single clear recommendation supported by a weighted scoring table that compared different approaches (such as Firebase Cloud Messaging vs. different Supabase integration patterns) with their trade-offs clearly explained.

All claims were required to be linked to official documentation or credible repositories, ensuring recommendations were grounded in authoritative sources rather than speculation. Any open questions or assumptions were explicitly called out for review, acknowledging that research inevitably reveals ambiguities that require additional discussion.


=== #120: Research: Data Privacy Compliance
*Status:* Closed | *Urgency:* 5 | *Difficulty:* 5  

This issue required identifying which data privacy regulations likely apply to the messaging and notifications module and outlining the compliance checks that must be performed before implementation. The critical constraint was that this was research only—no legal advice provided and no code written. The goal was to inform implementation decisions, not to provide definitive legal guidance.

The work began by mapping the scope of data being handled. This included personal data elements like user names, email addresses, device tokens for push notifications, and message metadata (timestamps, read/unread status, sender information). The flow of this data through the system was traced: data originates in the mobile app, flows to the backend server, and potentially flows to third-party push notification providers.

Based on the user locations and geographic markets the platform targets, applicable regulatory regimes were identified at a high level. For example, if the platform serves EU users, GDPR (General Data Protection Regulation) would apply; if it serves California residents, CCPA (California Consumer Privacy Act) would apply. All claims were sourced by linking to official regulatory text or authoritative guidance documents, not relying on secondary sources or interpretations.

The research documented the key compliance themes that should be addressed: establishing a lawful basis for processing each type of data (such as user consent, legitimate interest, or contractual necessity), ensuring the data collection follows minimization principles (collecting only what's necessary, not hoarding data), determining how long message metadata should be retained before deletion, what user rights must be supported (access requests, deletion requests, data export), special considerations for users under 18, international data transfer mechanisms if applicable, vendor data processing agreements with cloud providers, breach notification requirements and timelines, and baseline security control requirements.

Module-specific risk hotspots were highlighted: device push tokens are particularly sensitive because they can be intercepted or misused; message content and metadata could reveal sensitive information about recruiter-candidate interactions; logging and analytics systems may capture personal data incidentally; and backup systems must be secured to prevent access by unauthorized parties.

The research identified 6–8 concrete compliance checks that must be satisfied before implementation (e.g., "Retention - propose X months for message metadata"), a prioritized next steps list, and all evidence sourced with official regulation links. Any open questions or assumptions about jurisdictional scope, data residency preferences, or legal basis choices were flagged for review, recognizing that research reveals ambiguities that require expert judgment.


=== #155: Documentation Improvements (Tracking Issue)
*Status:* Open | *Urgency:* 3 | *Difficulty:* 3  

This issue serves as a master consolidation issue—a parent tracker for coordinating multiple sub-issues focused on revising the Milestone 2 documentation across Sections 1–3 based on feedback. Rather than treating each improvement as an isolated task, this issue recognizes that documentation revisions must be coordinated to ensure consistency, completeness, and adherence to established guidelines.

The goal is to ensure that all revisions are applied consistently, follow the established guidelines from the software design course, and are properly logged for traceability. The issue covers refinements needed across multiple sections of the documentation:

In Section 1, the work includes ensuring the synopsis briefly touches on all project activities (requirements engineering, implementation, testing) rather than just high-level marketing language; reviewing and refining derived goals to ensure they are meaningful and distinct from primary goals, not just restatements of what the system will do.

In Section 2 (the largest section), work includes enriching the Domain Rough Sketch with more detailed and concrete domain examples (not just abstract patterns), ensuring all key terminology is clearly defined with domain authority, distinguishing between employer and recruiter (they are not interchangeable), defining location and start date attributes properly, defining validity periods and benefits structure, including raw domain statements for concrete examples while maintaining appropriate abstraction levels, integrating all domain phenomena (events, actions, behaviors, entities) into a coherent whole rather than treating them separately, ensuring each function signature is tied to its operation description with proper parameter and return type documentation, refining epics and clearly linking features with complete user stories, adding detailed backgrounds to make personas vivid and immediately recognizable, ensuring each requirement has an ID and is justified by user stories with corresponding test cases, reviewing what belongs to domain versus presentation/application layers, and clarifying responsibilities in SOLID principles discussion.

Section 3 requires expanding the Validation Strategy from abstract scenarios into specific, concrete walkthroughs involving realistic stakeholder interactions.

All modifications use AsciiDoc change notations (highlight for additions, underline for paraphrased content, strikethrough for removals) and are recorded in a documentation logbook that tracks who made each change, which section was affected, and whether it was an addition or modification.



=== #161: Sub-Section Revision: Narrative (2.1.4)
*Status:* Closed | *Urgency:* 3 | *Difficulty:* 4  

This issue specifically targeted revision of Section 2.1.4 (Narrative) of the domain description to produce a clear, concrete, and conceptually sound narrative that combines abstracted concepts from concept analysis with specific examples from raw domain data. The feedback emphasized that the team wanted to use abstractions found in concept formation when narrating the domain, but also wanted to weave in some of the raw statements gathered through domain acquisition to give concrete examples for those general statements, rather than treating concept analysis as separate from practical domain storytelling.

The revision incorporated this feedback by updating the narrative to explicitly describe domain structure, entities, and relationships. Critically, it integrated key domain relationships such as the candidate-to-application-to-opening many-to-many relationships (a student can apply to multiple jobs, each job opening receives multiple applications), clearly explaining the multiplicities and dependencies. For example, explaining that each application links to exactly one student and one opening ensures readers understand the boundary between aggregate roots.

The narrative was enhanced to discuss special cases and edge scenarios that the happy-path flow would miss: what happens when a candidate accepts an offer after the deadline has passed (should this be allowed? what notification should be sent?), whether it's possible to make an error when entering the deadline in an offer (entering a date too early) and what the correction process should be (preserve the original as an error record, preserve decision trail), how duplicate applications submitted through different channels should be detected and consolidated (deduplicate intelligently), what happens when an opening is withdrawn mid-process after interviews have already begun (move applications to closed by employer with reason), how a candidate can withdraw an application after receiving an external offer (application state becomes withdrawn by candidate), what transparency should be provided when a student updates their resume after already submitting an application (show submitted version and indicate newer profile exists), and how reassignments should be handled mid-process (preserve decision trail).

The section was maintained in proper AsciiDoc formatting, using paragraphs, bullet points, and tables where necessary to ensure clarity and readability. The revised narrative was required to flow logically and complement the previously drafted sections (particularly 2.1.1 Domain Rough Sketch and 2.1.2 Terminology), creating a cohesive domain story rather than disconnected sections.

Success criteria required that the revised 2.1.4 clearly describe domain structure and entities, use raw statements and examples to support abstracted concepts, cover relevant edge cases and clarify potential ambiguities, be formatted properly in AsciiDoc, be internally consistent with related sections, and have all revisions logged in the documentation logbook.


=== #164: Sub-Section Revision: User Stories, Epics, and Features (2.2.1)
*Status:* Closed | *Urgency:* 3 | *Difficulty:* 3  

This issue required revising and improving Section 2.2.1 (User Stories, Epics, Features) according to Milestone 2 documentation guidelines and specific feedback. The feedback indicated that "the epics that you list are just the titles of the features that you describe below. More work needed here," which meant the team needed to do more than simply list epic names; they needed to create substantial user stories written from the user's perspective and ensure clear traceability between stories, features, and requirements.

The revision refactored the section to cleanly distinguish between Epics (which serve as high-level goals or titles like "Enable Efficient Candidate Discovery"), Features (which are specific functionalities that realize those epics like "Implement Swiping Interface" or "Create Match Notifications"), and User Stories (which describe what a user wants to accomplish and why like "As a recruiter, I want to quickly browse candidate profiles so that I can identify qualified candidates efficiently").

Each user story was required to follow the standard format: "As a [type of user], I want [goal] so that [reason/value]." This format ensures user stories focus on user needs rather than solution implementation. For each Epic, multiple user stories were created that collectively define the scope of user interaction, system functionality, and value delivered. For example, under "Enable Efficient Candidate Discovery" epic, user stories might include the need to search by skills, to see profile information relevant to decision-making, to receive recommendations, etc.

The revision ensured that Epics and Features aligned with the system's domain model and reflected real user needs identified through domain research. Clear traceability was established between User Stories (in 2.2.1), Features that implement those stories, and the Requirements (in section 2.2.3) that specify how features should behave. This traceability ensures that business needs (captured in user stories) flow directly into technical implementation, not allowing disconnects where requirements are implemented without clear business justification.

All entries were formatted in AsciiDoc, maintaining the structure and readability expected in professional documentation. Success criteria required that the updated section fully integrate feedback, list all Epics as concise and meaningful titles, include User Stories for each Epic written in user-centered language, ensure clear mapping between User Stories, Features, and Domain Requirements, be formatted according to AsciiDoc standards and ready for Milestone 2 submission, and have all revisions logged properly in the documentation logbook using the change notation system.


=== #227: Continuous Refactoring Log
*Status:* Closed | *Urgency:* 5 | *Difficulty:* 4  

This issue required creating a living log focused specifically on refactorings that deepen the domain model and improve business concept clarity, as opposed to refactorings that merely clean up code or optimize performance. This distinction is philosophically important because the team recognizes that meaningful refactoring is about improving how the code expresses domain concepts, not just about technical housekeeping.

This task responds to a principle in Domain-Driven Design that suggests refactoring is not complete when the code works—refactoring continues as team members develop deeper understanding of the domain. The log creates transparency into this evolution, making visible the thinking process that led to design decisions rather than just the final decision itself.

The continuous refactoring log established a file at `docs/refactoring/deep-insight-log.md` with a consistent entry structure for each refactoring: the "Smell/Trigger" describes what problem or code smell prompted the refactoring decision (e.g., "Class had multiple responsibilities mixing concern A and concern B"), the "Domain Insight" explains what was learned about the business rules or domain structure through analyzing the code (e.g., "Realized that concept A and concept B actually represent different bounded contexts that should be separate"), the "Refactor Performed" describes the specific code changes made (e.g., "Extracted concept B into its own service"), and the "Resulting Clarity/Invariants" explains how the refactoring clarified business rules or revealed new invariants that must always hold (e.g., "Now the system enforces the invariant that X can only exist when Y is present").

Each entry was required to explicitly explain why the refactor clarifies business concepts (rather than just being a technical improvement), not just describing what code changed. Entries reference any related diagrams or documentation pages that were updated as a result of the refactoring, maintaining consistency across the documentation as domain understanding evolves.

Success criteria required at least five dated entries, each tied to at least one domain concept or invariant, at least two entries linking to an updated diagram or documentation page, and continuous integration passes after all referenced refactors. This creates a searchable, chronological record of how the domain model evolved and deepens team understanding of why certain design decisions were made.



== Carlos Pepin (carlospepin23)
=== #228: Model Address as a Value Object and Integrate into StudentProfile 
*Status:* Closed | *Urgency:* 4 | *Difficulty:* 4  

This issue represented a focused Domain-Driven Design learning task that required modeling geographical location information—specifically an Address—as a Value Object rather than as a primitive collection of strings or as a standalone entity with its own identity. In Domain-Driven Design, the distinction between entities and value objects is fundamental. Entities are domain concepts that have continuous identity (a Student remains the same Student even if all their profile information changes, because they have a unique student ID), while value objects have no intrinsic identity; two Address objects with identical attributes are considered equal, regardless of whether they occupy the same memory location or database row. An Address is definitionally a value object because what matters is the location it represents, not some arbitrary ID assigned to it. The principle of modeling Address as a value object aligns with treating addresses as conceptually unified domain elements rather than scattering address information across multiple database columns and code properties. By treating Address as a cohesive unit, the code becomes more expressive and easier to reason about—when a function receives an Address parameter, developers immediately understand it represents a complete, coherent location.

The task required replacing primitive address fields that previously existed in the StudentProfile entity with a single reference to the new Address Value Object. Prior to this refactoring, StudentProfile might have had individual properties for street, city, state, zipCode, and country, a primitive approach that scatters domain knowledge across many small properties and offers no protection against invalid combinations (such as a valid US state paired with an invalid country code). By introducing Address as a value object, these scattered fields coalesce into a single Address property, allowing the Address object to encapsulate location logic and ensure invariants are maintained—for example, validating that if country is "United States", the state must be a valid US state code. A critical characteristic of value objects is immutability: once an Address object is created with specific values, those values cannot change. If StudentProfile needs to reference a different location, rather than modifying the Address object's properties, StudentProfile must be updated to reference an entirely new Address object. This immutability prevents subtle bugs where Address objects are unexpectedly modified elsewhere in the code, enables safe sharing of Address objects across the system without defensive copying, and aligns with functional programming principles that reduce side effects and make code more predictable.

The integration of the Address value object with StudentProfile required careful attention to aggregate boundaries and persistence considerations. In DDD terminology, an aggregate is a collection of domain objects treated as a unit, and StudentProfile serves as the aggregate root—the entry point through which external code interacts with the aggregate. All access to the Address should ideally flow through StudentProfile rather than allowing external code to bypass StudentProfile and manipulate Address directly, which maintains the integrity of the aggregate boundary and ensures consistency. The persistence layer, responsible for storing and retrieving objects from the database, needed updating to correctly handle the new value object structure. Depending on the architecture, Address might be persisted as embedded columns within the StudentProfile table, serialized as JSON in a single column, or as a relationship to a separate Address table (though this is less common for value objects). The persistence implementation had to maintain backward compatibility with existing data while supporting the new value object structure, potentially requiring migration scripts or compatibility layers to handle the transition from the old primitive field structure. Additionally, Data Transfer Objects (DTOs)—simplified objects used for transferring data across system boundaries such as JSON serialization for API responses—needed corresponding representations for the Address value object that could be easily converted to and from JSON.

The implementation required comprehensive testing at multiple levels and explicit success criteria to ensure quality. Unit testing focused on verifying the Address value object's core behaviors: immutability (attempting to modify an Address throws an exception or has no effect), value-based equality (two addresses with identical values are equal), and validation rules (invalid address combinations are rejected). Integration testing verified that Address works correctly within the StudentProfile context, while regression testing ensured that existing StudentProfile functionality remained unbroken. The success criteria explicitly defined what constituted completion: the Address object must be truly immutable with no way to change it after creation; the Address must have no identity field, reinforcing that it is identified by its values rather than by an ID; StudentProfile must correctly contain and reference the Address value object with proper aggregate boundary maintenance; all existing StudentProfile functionality and data must remain unaffected; and all relevant tests must pass successfully. This task served as a Lecture Topic Task, meaning its primary purpose was to provide practical learning experience in applying DDD principles. By working through the complete lifecycle of introducing a value object—from designing it through implementing immutability, ensuring value-based equality, integrating it with existing aggregates, updating persistence and DTOs, and testing thoroughly—the implementation gained concrete experience in one of DDD's core design techniques, informing future decisions about modeling other domain concepts in the system.


== Diego Pérez (diegoperez16)
=== #94: Aggregate Deletion Rules
*Status:* Closed | *Urgency:* 5  |  *Difficulty:* 5 

This issue required implementing cascade deletion logic for aggregates based on Domain-Driven Design principles, ensuring that when a StudentProfile aggregate is deleted, all directly dependent entities maintain data integrity and prevent orphaned records. The work was grounded in theoretical DDD deletion policies and required translating those policies into concrete database schema changes and application logic. An aggregate is a conceptual unit in Domain-Driven Design consisting of multiple domain objects that must be treated together to maintain consistency and enforce business rules. When the aggregate root (in this case, StudentProfile) is deleted, the entire aggregate must be disposed of cleanly, which means all entities that depend on StudentProfile for their existence must also be deleted. Specific foreign key relationships like Match.student_id, Application.student_id, and MentorAssignment.student_id were configured with ON DELETE CASCADE constraints at the database level, ensuring that deletion is enforced consistently regardless of which system layer initiates the deletion. This approach guarantees data integrity because the database prevents the existence of orphaned records (applications or matches pointing to deleted students).

However, not all dependent data should be cascade-deleted. Certain entities like AuditLog and Feedback were deliberately excluded from cascade deletion because they represent historical or accountability records that should persist even after the primary entity is removed. The implementation required careful discrimination between entities that logically belong within the aggregate boundary and those that represent external concerns. Additionally, the implementation included safety guardrails to prevent accidental bulk deletes in production environments, recognizing that cascade deletion is powerful but can cause catastrophic data loss if triggered unintentionally. The testing strategy validated cascade behavior through multiple scenarios: confirming that deleting a StudentProfile automatically removes all associated Match, Application, and MentorAssignment records; verifying that unrelated entities like AuditLog remain untouched; ensuring all unit and integration tests pass; and validating that schema changes are properly documented and reviewed. This lecture topic task served to deepen understanding of how DDD principles around aggregates and their boundaries translate into concrete database design decisions that maintain system consistency and prevent data corruption.

The implementation represented the intersection of theoretical domain design and practical database engineering. While DDD provides principles for how aggregates should behave logically, those principles must be realized through database constraints and application code. The ON DELETE CASCADE constraint at the database level provides a defense-in-depth approach where consistency is enforced even if application code fails to delete dependent records. This redundancy is essential in production systems where recovery from data corruption is expensive and disruptive. By documenting the deletion policy and its implementation, the team created a foundation for understanding how other aggregates in the system should handle their own deletion behavior, preventing inconsistent approaches and ensuring the entire system maintains a coherent deletion strategy.


=== #145: Research: Building 1-on-1 Communication Systems
*Status:* Closed | *Urgency:* 4  |  *Difficulty:* 4

This issue required conducting comprehensive research into architectural patterns, technologies, and best practices for implementing scalable, real-time one-on-one chat systems in web applications. The research was explicitly scoped as investigation only—no production code was written—but all findings were structured to be immediately actionable for implementation planning. The research packet covered core architectural decisions including whether to use client-server versus peer-to-peer approaches, synchronous WebSocket communication versus asynchronous polling, and which real-time frameworks (WebSockets, Socket.IO, Firebase Realtime Database) offered the best tradeoffs for the project's specific requirements. Message delivery guarantees were investigated, including how to implement acknowledgment patterns, retry logic, and reliability mechanisms that ensure no messages are lost or duplicated even when network failures occur. The research explored storage strategies, deciding whether to keep messages ephemeral or persistently stored, and what implications each choice had for the user experience and system scalability. End-to-end encryption implementation models were analyzed to understand how to implement secure private conversations without exposing message content to the platform operator.

Supporting features were thoroughly researched, including user presence indicators (showing when other users are online), typing status (displaying when another user is actively composing a message), and message status indicators (sent, delivered, read) that provide users with confidence about message delivery. The research covered authentication and authorization mechanisms for ensuring that private one-to-one conversations are truly private and that only the intended participants can access the conversation. Horizontal scaling concerns were examined, including how to distribute WebSocket connections across multiple servers, manage session affinity, and handle message routing between clients connected to different servers. At least 6–8 actionable best practices were compiled and documented, all referencing open-source projects, architecture blogs, or production-level examples to ensure recommendations were grounded in authoritative sources. The research packet included a single clear recommendation supported by a weighted scoring table that compared different approaches with their tradeoffs clearly explained, enabling the team to make informed technology selection decisions that would have long-term implications for system maintainability and performance.

The work represented essential upfront investment in understanding the design space before committing to specific implementation technologies. By researching thoroughly, the team avoided common pitfalls like selecting a real-time framework that worked well for 100 concurrent users but couldn't scale to 10,000 users, or choosing an approach with poor offline resilience that created poor user experience when network connectivity was interrupted. The research synthesis process transformed raw technical information from multiple sources into a coherent narrative that the team could use for decision-making. All claims were required to be linked to official documentation or credible repositories, ensuring that recommendations were not speculative but grounded in demonstrated, validated approaches used in production systems.


=== #146: Research: Building Group Chat Communication Systems
*Status:* Closed | *Urgency:* 4  |  *Difficulty:* 4

This issue required researching best practices for implementing group chat functionality, which introduces significantly different architectural and scaling challenges compared to one-on-one messaging. While one-on-one chat is relatively simple (coordinating only two participants), group chat must efficiently manage message broadcasting to multiple concurrent recipients, coordinate state across many clients, handle participant role hierarchies (administrators, moderators, read-only participants), and optimize for high message volume without degrading performance. The research covered message broadcasting using socket room architecture, where the server maintains groups of connected clients and efficiently routes messages to all participants in a group without sending them to unrelated clients. Channel and thread management were investigated, including how to organize conversations by topic, allow threaded responses (conversations within conversations), and provide both flat and hierarchical conversation structures depending on user preference. Message history persistence strategies were analyzed, determining the tradeoffs between storing all messages indefinitely versus implementing retention policies that balance storage costs with user expectations about historical message availability.

Participant role and permission systems were researched to understand how to implement granular access control where some users can post messages, others can only read, some can moderate by deleting inappropriate content, and administrators can manage permissions themselves. Scalability for high-volume deployments was given particular attention, including techniques like message throttling (limiting the rate at which users can send messages to prevent spam), pagination (loading messages in batches rather than all at once), and rate-limiting to maintain system stability. Mention handling for @user and @all notifications was explored, including how to efficiently identify which users need to be notified and deliver notifications without overwhelming users with alerts. Message editing, deletion, and versioning trails were analyzed to maintain audit trails and allow users to correct mistakes without losing the historical record of what was said. Frontend performance optimization techniques were covered, including how to maintain a responsive interface even when a chat room has high activity with thousands of messages. At least 6–10 clear technical best practices were compiled with references to production-quality architectures or well-maintained open-source implementations. The research specifically addressed both backend engineering needs (server architecture, database design, scaling strategies) and frontend considerations (UI responsiveness, message rendering performance, state management), ensuring that the team had a complete picture of the challenges involved.

The research distinguished group chat from one-on-one chat through careful analysis of their unique requirements. For instance, one-on-one chat needs simple pair-wise routing, while group chat requires efficient broadcast mechanisms. One-on-one chat can often assume both participants are interested in all messages, while group chat must handle scenarios where some participants mute threads or leave groups. This distinction meant that copying one-on-one chat architecture and simply adding multiple recipients would create a system that couldn't scale to real group chat use cases. By researching group chat separately and thoroughly, the team avoided this architectural mistake and instead designed a system with appropriate mechanisms for group communication from the start.


=== #176: Diagram Functionality Flow Implementation in Documentation
*Status:* Closed | *Urgency:* 3  |  *Difficulty:* 5  

This issue required creating and integrating functionality flow diagrams within the Milestone 2 documentation to provide visual representations of the system's behavior and how core functionalities interact across different architectural layers. The goal extended beyond simply creating attractive visuals; the diagrams were meant to complement textual explanations in the software architecture and design sections, allowing readers to quickly grasp system behavior without reading lengthy prose. The diagram needed to capture main data and interaction flows between system layers, showing user actions and inputs (such as login, profile creation, or other user-initiated events), followed by application services and domain logic interactions, including database or persistence operations and external API calls when applicable. Emphasis was placed on making data transformations and decision points visible, allowing readers to trace the path of information through the system and understand where critical business logic decisions occur.

The diagram was required to use standard UML or flowchart notation (activity diagrams, sequence diagrams, or custom system flow diagrams) that would be immediately recognizable to developers and architects. Critical emphasis was placed on using scalable vector formats (SVG or PDF) to ensure quality at any zoom level or when printed, explicitly avoiding raster formats like PNG or JPEG that would become pixelated when enlarged or printed at large size. The diagram was integrated into AsciiDoc documentation as an embedded image or block, maintaining consistency with the rest of the documentation format. The diagram had to directly complement written architectural explanations rather than replace them, meaning that readers should be able to understand the architecture by reading the text alone or by looking at the diagram alone, but receive enhanced understanding from both together. The diagram was required to align with software architecture documentation and usage scenarios, illustrating logical consistency between system modules and user behavior. Success criteria explicitly required that the diagram capture main data and interaction flows between system layers, use standard notation, be inserted in AsciiDoc format, directly complement written architectural explanations, be scalable and legible, and that all modifications be recorded in the documentation logbook using established change notation standards.

The task represented a significant effort because diagrams require both technical accuracy (correctly representing system architecture) and clarity for the intended audience (developers with varying levels of architectural knowledge). Creating diagrams that satisfy both requirements is genuinely difficult, as oversimplification for clarity can lose important technical details, while comprehensive accuracy can create overwhelming diagrams that obscure the main concepts. The effort to integrate diagrams into the documentation and ensure they were tested for clarity and correctness was significant. The diagram served as a valuable communication tool, converting abstract architectural concepts into visible flows that could be discussed in team meetings, used in onboarding new developers, and referenced when making architectural decisions about future changes to the system.


=== #144: Weekly Report #5
*Status:* Closed | *Urgency:* 10  |  *Difficulty:* 10 

This issue represented the fifth weekly status report during Milestone 2, serving as a critical checkpoint for tracking team progress and maintaining alignment toward milestone completion. The weekly report format provided an essential mechanism for documenting what each functional team accomplished during the week, identifying any blockers or obstacles they encountered, and ensuring accountability across all team members. The specific week covered by this report included several implementation accomplishments: the team added a toggle switch in the settings menu allowing users to switch between light and dark themes, implemented local storage persistence so user theme preferences would survive application restarts and maintain consistency across sessions, applied system-level dark mode preference detection so the application would respect the operating system's dark mode setting by default, began comprehensive testing across multiple devices to ensure user interface consistency across different screen sizes and platforms. In parallel, the research team investigated accessibility standards and best practices for implementing dark mode to ensure it met accessibility guidelines for users with visual impairments or color blindness, while the documentation team updated the technical guide and implementation documentation to reflect the new user interface changes.

The weekly report served multiple purposes beyond simple progress tracking. It provided visibility to stakeholders about what work was being performed and what value was being delivered each week. It created a historical record of project progress that could be analyzed to identify velocity trends, predict delivery dates, and understand which types of tasks consistently consumed more effort than estimated. It surfaced blockers and obstacles early enough that they could be addressed before they derailed the schedule. It fostered team accountability by making each team's progress (or lack thereof) visible to peers, creating positive peer pressure to maintain productivity. The success criterion for this weekly report was simply to provide an accurate status update capturing the week's progress, allowing managers and team leads to understand velocity, identify patterns, and address any emerging issues early enough to course-correct before they impact milestone deadlines.

The weekly report format also served as a cadence for team synchronization. By establishing a regular weekly rhythm of reporting, the team created a predictable pattern for status updates that prevented surprises. Blockers and risks that might not be obvious early in a week could be identified by mid-week, and team members could work on addressing them by the time the weekly report was due. This cadence also served a psychological function, giving each team a weekly opportunity to celebrate accomplishments and mark progress toward the larger milestone goal.


=== #199: Milestone #2 Presentation
*Status:* Closed | *Urgency:* 10  |  *Difficulty:* 4 

This issue coordinated the preparation of the Milestone 2 presentation, which served as the formal review and demonstration of all work completed by the team during the second milestone cycle. The presentation provided an opportunity for all team leads representing the Research, Functionality, Design, and Documentation teams to collaborate and compile a comprehensive overview of their achievements, challenges, and lessons learned. The presentation highlighted major accomplishments including the implementation of the matching algorithm that enables job-seekers and recruiters to discover each other effectively through a swiping-based interface, the setup and integration of Supabase (a backend-as-a-service platform) with the Flutter mobile development framework to provide real-time database capabilities and authentication features, the creation of distinct account type flows ensuring that students and recruiters have fundamentally different user experiences tailored to their specific needs and workflows, and the completion of documentation improvements that were recommended during the previous milestone evaluation. Each team lead was responsible for contributing specific, quantifiable details about their team's achievements, ensuring that the presentation accurately represented the scope and quality of work completed rather than providing vague generalities.

The presentation served as the formal communication mechanism between the development team and stakeholders including course instructors, project advisors, and anyone else invested in the project's success. It provided an opportunity to demonstrate progress in a structured, coherent narrative rather than a chaotic listing of disconnected accomplishments. By organizing the presentation by team and by major feature area, the presentation made clear how different teams' work contributed to the overall system. The presentation also served as an opportunity to identify and discuss challenges encountered, explaining how obstacles were overcome or what remains to be addressed in future milestones. This transparency about challenges was as important as celebrating accomplishments, as it demonstrated realistic assessment of project status and maturity in problem-solving. The success criterion was that specific, quantifiable details about team achievements could be included in the milestone presentation, providing stakeholders with clear evidence of progress and value delivered.

The presentation preparation process also served as a forcing function for comprehensive project review. In preparing to present accomplishments to stakeholders, team leads typically review all work completed, identify gaps or inconsistencies, and gain a holistic view of what was actually delivered versus what was planned. This review process often surfaces issues that had been missed in the chaos of day-to-day development, allowing them to be documented and planned for in the next milestone.


=== #192: Weekly Report #6
*Status:* Closed | *Urgency:* 10  |  *Difficulty:* 4 

This issue documented the sixth weekly status report during Milestone 2, continuing the pattern of systematic progress tracking and team synchronization. The work accomplished during this week focused on continuing the user interface improvements from previous weeks, specifically maintaining momentum on dark mode implementation and theme switching features. The week included adding theme toggle functionality in the settings menu, ensuring that user preferences were persisted locally through browser or app storage mechanisms, implementing detection and application of system-level dark mode preferences so the application respected operating system settings by default, conducting extensive testing across multiple devices to ensure the user interface displayed consistently and responsibly on different screen sizes and device capabilities. In parallel, the research team investigated accessibility standards relevant to dark mode implementation to ensure the feature met Web Content Accessibility Guidelines (WCAG) standards for users with visual impairments, while the documentation team updated the technical guide to document the new theme switching feature for future developers and architects who would maintain the codebase.

The weekly report served the critical function of maintaining executive visibility into team progress, enabling early identification of any schedule risks, and creating an auditable record of work completed. By maintaining consistent weekly reporting throughout the milestone, the team created a detailed historical record that could be analyzed to understand project dynamics, team productivity, and factors that either accelerated or hindered progress. The format and regular cadence of these reports also ensured that no major work or accomplishments were overlooked or forgotten by the time formal milestone presentations occurred. The success criterion remained consistent: to provide an accurate weekly progress report capturing team accomplishments and any blockers identified during the week.

The sixth week report's focus on continuing dark mode implementation demonstrated the iterative nature of software development, where features are not implemented in a single effort but refined and extended over multiple development cycles. This pattern of incremental progress, visible through weekly reporting, gave stakeholders confidence that work was progressing and helped identify any weeks where progress stalled, indicating potential problems requiring intervention.


=== #193 – Weekly Report #7
*Status:* Closed | *Urgency:* 10  |  *Difficulty:* 4

This issue recorded the seventh and final weekly status report for Milestone 2, documenting the conclusion of the milestone work cycle. This final week's activities mirrored the focus areas of the previous weeks, indicating the continuation and refinement of ongoing work rather than major new initiatives being started at the end of the milestone. The team continued implementing the theme switching feature in the settings menu, persisting user preferences locally to survive application sessions, applying system-level dark mode detection by default, conducting device testing for user interface consistency, researching accessibility standards for dark mode compliance, and updating technical documentation. The final week of a milestone serves multiple purposes beyond just reporting progress: it provides a final accounting of what was accomplished, identifies any loose ends or incomplete work that needs to be carried into the next milestone, and allows the team to assess whether the milestone goals were met or whether there are unfinished items requiring continuation.

This final weekly report served as a transition point, documenting that Milestone 2 work was completed to specification while preparing for the beginning of Milestone 3 with clear documentation of what was achieved and what remained to be done. The report provided the baseline for understanding what carried over into the next milestone and what new work would be started. By maintaining consistent reporting through the final week of the milestone, the team ensured that no work was lost or forgotten in the rush to close out the milestone. The success criterion remained the same as previous weeks: to provide an accurate weekly progress report capturing team accomplishments and any blockers, but with the added significance that this report closed out an entire milestone's work.

The final weekly report of a milestone is often the most detailed, as it must comprehensively cover not just the week's accomplishments but also provide a summary of the entire milestone's work, identify what was planned but not completed, and establish the baseline for the next milestone's planning.


=== #216: Explore Prior Art for Modeling
*Status:* Open | *Urgency:* 5  |  *Difficulty:* 5  

This issue required investigating and documenting existing academic, industry, and open-source work related to modeling approaches and methodologies that could inform the design and architecture of the Professional Portfolio system. The objective was not to generate original research but rather to synthesize and curate existing knowledge from authoritative sources to guide the team's modeling phase. The research was to cover prior art and methodologies relevant to software engineering modeling in general, identify best practices and tools applicable to the specific project context, and document findings that could directly guide the project's modeling approach. The research summary needed to outline at least three distinct relevant modeling approaches from different schools of thought or practitioners, identify potential frameworks or tools (such as specific diagramming tools, modeling languages, or methodological frameworks) that could support the Professional Portfolio system modeling work, establish clear linkage between findings and the project's specific modeling requirements (not just generic best practices), and provide properly formatted references in APA or IEEE format to ensure credibility and enable team members to explore sources in depth if needed.

The investigation of prior art served to avoid reinventing the wheel and to apply proven approaches to the Professional Portfolio's specific challenges. By reviewing existing modeling techniques documented in academic literature, industry best practices, and open-source projects, the team could learn from others' experiences and avoid common pitfalls. For instance, Domain-Driven Design modeling approaches have been extensively documented and refined over decades, and leveraging that body of knowledge was more efficient than developing a new modeling approach from scratch. Similarly, modeling languages like UML have evolved through extensive use and feedback to support various modeling needs effectively. The research also served to expose the team to diverse modeling perspectives, preventing them from defaulting to overly narrow approaches and encouraging consideration of multiple possibilities.

The research deliverable consisted of a document that synthesized findings from multiple sources into a coherent narrative that the team could use for decision-making. Rather than overwhelming the team with raw research materials, the synthesis process filtered that material through the lens of "what is relevant to the Professional Portfolio project?" This curation ensured that the team could make effective use of prior art without spending excessive time absorbing information that was not directly applicable. All claims were required to be linked to authoritative sources, ensuring that recommendations were not speculative but grounded in demonstrated, validated approaches.


=== #262: Milestone #3 Presentation
*Status:* Open | *Urgency:* 6  |  *Difficulty:* 5

This issue coordinates the preparation of the Milestone 3 presentation, serving as the formal review and demonstration of all work completed during the third milestone cycle. Similar to the Milestone 2 presentation, this issue provides an opportunity for all team leads to collaborate and compile a comprehensive overview of achievements and obstacles faced during this milestone. The presentation highlights major accomplishments including the implementation of the matching algorithm for connecting job-seekers and recruiters, the setup of Supabase integration with Flutter, the creation of distinct account types for different user personas, and the completion of documentation fixes recommended during previous evaluations. Each team lead contributes specific, quantifiable details about their team's achievements to ensure the presentation accurately represents the scope and quality of work completed during Milestone 3, rather than providing generic overviews. The presentation also serves as an opportunity to discuss challenges encountered, explaining how obstacles were overcome or what remains to be addressed in future work, demonstrating both achievement and realistic assessment of project status.

The Milestone 3 presentation serves as a capstone for the third development cycle and provides a formal communication mechanism to stakeholders about the project's progress and direction. By the third milestone, stakeholders expect to see significant system functionality implemented, not just architectural foundations. The presentation should demonstrate that the system is becoming tangible and useful, with visible features that end-users would recognize. The presentation also provides an opportunity to discuss any significant pivots or course corrections that occurred during the milestone, explaining the reasoning behind changes to the originally planned work. The success criterion is that specific, quantifiable details about team achievements are included in the milestone presentation, providing stakeholders with clear evidence of progress delivered during this cycle and confidence in the project's continued momentum.

The preparation of the Milestone 3 presentation follows a similar pattern to Milestone 2 but benefits from the team's experience with milestone presentations, typically resulting in more polished and coherent presentations than earlier attempts. By the third milestone, the team has developed experience in what information is most important to communicate, how to present progress in a compelling narrative, and how to address questions from stakeholders effectively.


=== #263: Weekly Report #1
*Status:* Open | *Urgency:* 9  |  *Difficulty:* 4

This issue initiates the weekly status reporting cycle for Milestone 3, providing the first checkpoint for tracking progress during the third milestone. The objective remains consistent with previous weekly reports: to provide an update on each team's progress, ensure alignment toward milestone completion, track accountability, identify blockers early, and keep everyone on pace with project deliverables. This first week of Milestone 3 captured the team's initial accomplishments including adding a theme toggle in the settings menu, storing user preferences locally for persistence across sessions, applying system preference detection for dark mode by default, beginning comprehensive device testing for user interface consistency, researching accessibility standards for dark mode, and updating technical documentation to reflect these new interface changes. The weekly report serves to establish a baseline understanding of project velocity and team productivity at the beginning of the milestone, against which future weeks' progress can be measured.

The first weekly report of a new milestone is particularly important because it sets the tone for the entire milestone and establishes whether the team is starting with strong momentum or facing early obstacles. A strong first week where the team accomplishes its planned work on schedule suggests the milestone will likely proceed smoothly. Conversely, a weak first week where blockers emerge or progress is slower than expected provides early warning that the milestone timeline may be at risk. The success criterion is simply to provide an accurate weekly progress report capturing team accomplishments and any blockers identified during the week, but with the added significance that this report establishes the baseline for the entire Milestone 3 cycle.

The first report also serves as an opportunity to verify that the team has successfully transitioned from Milestone 2 to Milestone 3, that planning for the milestone is clear, and that all team members understand their assigned work for the milestone. Any confusion about priorities or assignments typically emerges in the first weekly report and can be addressed before it impacts multiple weeks of work.


=== #264: Weekly Report #2
*Status:* Open | *Urgency:* 9  |  *Difficulty:* 4 

This issue documents the second weekly status report for Milestone 3, continuing the systematic tracking pattern established at the beginning of the milestone. The work accomplished during this week follows similar patterns to the previous week, with teams adding theme toggle functionality, persisting user preferences, implementing system dark mode detection, conducting device testing for consistency, investigating accessibility standards, and updating technical documentation. The weekly report serves to maintain continuous visibility into team progress, enabling early identification of schedule risks, and creating an auditable record of work completed throughout the milestone cycle. By week two of the milestone, any initial confusion about assignments or priorities should have been resolved, and the team should be settling into a productive rhythm. If week two shows significantly less progress than week one, it may indicate that week one's progress was artificially inflated (perhaps by completing previously-prepared work) or that obstacles have emerged.

The second week report provides confirmation that the team has successfully established the working rhythm for the milestone and is not experiencing unexpected obstacles. It also begins to provide trend data about team velocity and productivity that can be used to forecast whether the milestone will complete on schedule. The success criterion remains consistent: to provide an accurate weekly progress report capturing team accomplishments and any blockers identified during the week.

The second week report also serves as an inflection point where course corrections can still be made without significant impact. If serious issues are identified in week two, there is still sufficient time to address them before the end of the milestone. However, waiting until week four or five to address issues discovered in week two can result in the milestone missing its deadline.


=== #265: Weekly Report #3
*Status:* Open | *Urgency:* 9  |  *Difficulty:* 4

This issue records the third weekly status report for Milestone 3, representing the first report of the second half of the milestone (assuming a two-week reporting structure per half). At this midpoint, the weekly report should demonstrate either strong, sustained progress or identify any significant issues that are preventing on-schedule completion. By the midpoint of a milestone, approximately half of the planned work should be completed, providing clear visibility into whether the milestone will finish on schedule or face delays. The work accomplished during this week continues the implementation and refinement of features, following established patterns of theme switching, user preference storage, system dark mode detection, device testing, accessibility research, and documentation updates. The weekly report serves to maintain continuous visibility into team progress and create an auditable record of work completed throughout the milestone cycle.

The third week report is particularly significant because it represents the midpoint assessment of the milestone. If the milestone is on track, the report should show that approximately 50% of planned work is complete. If significantly less work has been completed, it indicates the milestone is at risk of missing its deadline and corrective action is needed. If significantly more work than expected has been completed, it suggests either the scope was underestimated or the team is operating more efficiently than anticipated. In either case, the midpoint report is the trigger for adjusting plans if needed. The success criterion remains consistent: to provide an accurate weekly progress report capturing team accomplishments and any blockers identified during the week.

The midpoint of a milestone is often when major changes to scope or schedule are decided. If the milestone is behind schedule, trade-off decisions must be made about which features to include in the current milestone versus deferring to future work. If ahead of schedule, decisions must be made about whether to expand scope to include additional work or accelerate the completion timeline.


=== #266: Weekly Report #4
*Status:* Open | *Urgency:* 9  |  *Difficulty:* 4 

This issue documents the fourth weekly status report for Milestone 3, representing the midpoint checkpoint during the second half of the milestone. At this point in the milestone cycle, the team should be approaching final completion of major work, with focus shifting toward quality assurance, final testing, and preparation for the milestone review. The work accomplished during this week continues implementation and refinement of features, following established patterns of ongoing development activities. The weekly report serves to maintain transparency about team progress and ensure alignment toward milestone completion objectives. By week four of a typical milestone, roughly 75% of planned work should be completed, with the remaining 25% consisting of final touches, testing, and documentation refinement.

The fourth week report represents the final checkpoint before the milestone conclusions and presentations. If the milestone is on track, this report should show that work is nearly complete and the team is focused on quality and completeness rather than new feature implementation. If the milestone is behind schedule, this report should trigger urgent action to prioritize remaining work and make final scope trade-off decisions. The success criterion remains consistent: to provide an accurate weekly progress report capturing team accomplishments and any blockers identified during the week.

At week four, any work that remains incomplete should have a clear plan for completion before the milestone ends. Surprises or new obstacles discovered this late in the milestone have limited time for resolution and can easily result in missed deadlines.


=== #267: Weekly Report #5
*Status:* Open | *Urgency:* 9  |  *Difficulty:* 4  

This issue documents the fifth and final weekly status report for Milestone 3, representing the completion of the weekly reporting cycle for this milestone. The work accomplished during this concluding week should represent final touches, last-minute bug fixes, documentation completion, and preparation for the milestone presentation and review. This week's report serves as a final accounting of what was accomplished during the entire milestone, identifies any loose ends or incomplete work that needs to be carried into future milestones, and allows the team to assess whether milestone goals were met or whether there are unfinished items requiring continuation. The weekly report maintains the pattern established throughout the milestone, providing continuous visibility into team progress and creating an auditable record of work completed.

The final weekly report of Milestone 3 serves as both a conclusion to the current work and a transition point to future work. It documents what was successfully completed, what technical debt or incomplete work was left for future resolution, and what lessons were learned during the milestone that should inform future milestone planning. By maintaining consistent reporting through the final week of the milestone, the team ensures that no work is lost or forgotten in the rush to complete and prepare for milestone presentations. The success criterion remains the same as previous weeks: to provide an accurate weekly progress report capturing team accomplishments and any blockers, but with the added significance that this report closes out an entire milestone's work cycle.

The final weekly report of a milestone is typically the most comprehensive, as it must provide not just the week's accomplishments but also serve as a summary of the entire milestone, establish the baseline for the next milestone's planning, and provide historical data that can inform future project planning and estimation.


== Osvaldo Figueroa (Osvaldoo1414)

=== #118: LTT 26: Identify Naïve vs Deep Models
*Status:* Closed | *Urgency:* 5  |  *Difficulty:* 5

This issue required conducting a theoretical analysis of the current domain model to distinguish between superficial, naïve elements and genuinely deep domain concepts that add real value to the system. The objective was to refine the Professional Portfolio model toward deeper concepts that would meaningfully improve matching quality between students and recruiters, provide useful insights for recruiters to make better hiring decisions, and create genuine opportunities for students. In Domain-Driven Design terminology, a naïve model emphasizes cosmetic elements like profile pictures and biographical statements as central features, treating them as primary decision-making factors, whereas a deep model focuses on substantive domain concepts like demonstrated skills, recruiter-specific matching rules, candidate eligibility criteria, evidence of capability, and signals of genuine interest. The analysis involved classifying existing model elements as either naïve or deep, highlighting specific examples of superficial features that add little value, and identifying deeper domain concepts worth emphasizing. By making this distinction explicit, the team could deliberately choose to invest effort in modeling concepts that genuinely solve user problems rather than spending energy on superficial cosmetics that would not improve matching quality or user satisfaction.

The work required systematic comparison of naïve versus deep elements in table format, allowing the team to see at a glance which model elements provided genuine business value and which merely occupied space. Proposed bounded contexts were documented (such as Profiles, Matching, Recruiter Engagement, and Events), clarifying which domain concepts belonged together conceptually and which should be separated for maintainability and clarity. Core domain concepts were explicitly distinguished from supporting or generic domains, recognizing that not all model elements deserved equal attention. The analysis defined a pipeline for deeper matching algorithms and meaningful metrics that could drive continuous improvement in the matching process. Documentation of risks, mitigations, and a domain glossary ensured that the team shared a common vocabulary for discussing the model. The deliverable was saved in the repository, creating a permanent record of the analysis that could be referenced when making future design decisions about which concepts to model deeply versus superficially.

The exercise of analyzing naïve versus deep models served as a valuable learning opportunity about Domain-Driven Design principles. It demonstrated that simply having more data about users (more profile fields, more photos, more text) does not necessarily create a better system if that data is not structured to reflect genuine business domain concepts. For instance, having a dozen photos of a candidate is naive from a matching perspective, but having evidence of specific technical skills relevant to a recruiter's open positions is deep. This distinction informed future modeling decisions and helped the team prioritize what information to capture and how to structure it in the domain model. The analysis also helped identify which model elements should trigger notifications, affect matching algorithms, or trigger recruiter actions, versus which elements were primarily cosmetic.


=== #116: Research: Group Chat vs. One-on-One Communication Best Practices
*Status:* Closed |  *Urgency:* 6  |  *Difficulty:* 5

This issue required conducting research to understand and document best practices for when group chat communication should be used versus when one-on-one private messaging should be preferred in team collaboration environments. The research was motivated by recognition that both communication modalities serve different purposes and have distinct tradeoffs: group chat enables transparency, visibility of decision-making processes, and inclusive participation where all team members can see context and contribute, but carries the risk of information noise where excessive messages obscure important discussions and create cognitive overload. One-on-one communication enables focused, confidential discussion of sensitive topics and prevents disruption of shared channels, but carries the risk of siloing information where important decisions and knowledge remain hidden from the broader team, potentially duplicating effort or creating inconsistency across the organization. The research involved analyzing real-world communication platforms (Slack, Discord, LinkedIn, and similar tools) to understand patterns of when teams chose group versus one-on-one communication and what outcomes resulted from each choice.

The research identified specific scenarios where each communication method was most effective: brainstorming decisions might be better in group chat where multiple perspectives could be shared simultaneously, while performance feedback or sensitive personnel discussions should remain private. The research highlighted risks of overuse in either direction, including how exclusive reliance on group chat created overwhelming notification loads and important messages got lost, while excessive use of private messages created siloed knowledge where decisions made in private conversations were not visible to the broader team. The research provided practical recommendations for balancing both methods in team workflows, considering factors like message complexity, sensitivity level, urgency, and stakeholder relevance. Communication tool selection, etiquette norms, and communication tone considerations were explored to foster productivity and clarity. The deliverable was a concise set of communication guidelines that the team could adopt as standard practice, making it easy for team members to quickly assess whether a particular communication event should occur in a group channel or in a private conversation.

The research served as important preparation for the Professional Portfolio project's own communications patterns, ensuring that the team established clear, consistent practices from the start rather than developing chaotic communication habits that would create inefficiency and misalignment. By establishing guidelines upfront, the team prevented the common scenario where some communications were duplicated across both group and private channels, others were only in private channels and invisible to stakeholders, and still others generated excessive noise in group channels with marginal relevance to most participants. The research also provided justification for those communication guidelines based on real-world evidence from how other successful teams managed communication.

=== #215: Define Integration Strategy between Profile and Matching Subsystems
*Status:* Closed |  *Urgency:* 6  |  *Difficulty:* 6

This issue required performing critical architectural planning work by defining and documenting the integration strategy for reliable communication between two core subsystems in the Professional Portfolio application: the Profile subsystem (responsible for managing user data including skills, preferences, and availability) and the Matching subsystem (responsible for calculating compatibility and rankings based on profile information). The problem being addressed was that integration points between these subsystems were previously undefined, which created risks of data inconsistency (where Profile and Matching might have conflicting views of the same data), coupling (where changes in one subsystem would force changes in the other), and scalability issues (where tight coupling would prevent independent scaling or deployment). The work involved analyzing potential integration problems that could arise, such as what happens when a user updates their profile while a matching calculation is in progress, or how to ensure that the Matching subsystem always has current information without requiring Profile to notify Matching of every change. Three distinct architectural strategies were compared: Shared Kernel where both subsystems share a common domain model (simplified and tightly coupled), Translation Layer where communication occurs through carefully designed interfaces and events (more complex but flexible), and Bounded Context Separation where subsystems are fully isolated (most complex and maintaining eventual consistency).

The task required selecting the most suitable architectural approach with clear justification. After analysis, the Translation Layer strategy using asynchronous, event-driven communication was chosen as the optimal balance between flexibility, autonomy, and simplicity. The chosen strategy was documented in an AsciiDoc file at `docs/strategic-design/integration-strategy.adoc` with detailed descriptions of how Profile and Matching subsystems communicate through events. The documentation described the strategy in detail, explained the reasoning behind choosing it over the alternatives (Shared Kernel creates high coupling and coordination overhead, while Bounded Context Separation adds unnecessary complexity for this project's current scale), and included simplified ASCII diagrams showing how Profile and Matching subsystems communicate through events. Risks associated with the strategy were documented (such as the possibility of eventual inconsistency if events are lost) and concrete mitigations were proposed (such as retry logic and compensation events). Testing recommendations ensured that developers would validate the integration works correctly under various failure scenarios.

The integration strategy served as a bridge between abstract Domain-Driven Design principles and concrete implementation decisions. By explicitly choosing a translation layer with event-driven communication, the team established a foundation that would allow each subsystem to evolve independently while maintaining the information flow necessary for matching to function. This strategy prevented the common problem where two subsystems become so tightly coupled that they must be changed together, making the codebase increasingly difficult to modify as the system grows. The documentation of the strategy created a shared understanding of why events should be used, what events should be published, and how each subsystem should respond to events from the other. This clarity prevented later developers from making ad-hoc changes that would undermine the architectural intention.


== Yandré Caban (yandrecaban)

=== #180: Design Chat Screen Layout – UX Planning
*Status:* Closed | *Urgency:* 4  |  *Difficulty:* 4 

This issue tasked the UX design team with creating the structural layout and interaction flow for the main conversation screen within the messaging module of the Professional Portfolio application. The objective was to define how users would experience the core chat interface, establishing consistent patterns for both one-on-one and group chat conversations. The work required designing several key interface elements: the chat header area (which would display the name of the person or group being messaged, include a back button to navigate away from the chat, and potentially show optional status indicators such as online/offline status), a scrollable message list area (where the history of messages would be displayed with proper visual hierarchy and readability), and the placement of the input bar (where users would compose and send new messages). Beyond these basic structural elements, the design needed to ensure proper spacing and visual hierarchy so that no element felt cramped or overwhelming, verify sufficient contrast between text and backgrounds to meet accessibility standards, and create a responsive layout that would adapt gracefully to different window sizes and device orientations. The design also needed to consider both the empty chat state (showing what the interface looks like when a conversation is first opened before any messages are loaded) and the loaded chat state (showing the interface populated with a conversation history), ensuring consistency and clarity in both scenarios.

The success criteria required that a chat screen layout mockup be ready in Figma or an equivalent design tool, demonstrating the visual hierarchy and responsive behavior of the interface. The layout had to clearly distinguish between header, message list, and input areas through visual design, spacing, and color, so users could instantly understand the purpose of each area. The design had to demonstrate responsive behavior that adapted well to different screen sizes, from mobile phones to tablets to desktop browsers, without losing usability on any platform. The testing approach involved reviewing the mockup with developers to ensure technical feasibility, validating alignment with the existing Flutter design system to maintain consistency with other app screens, and confirming that all interface elements fit within safe display zones and account for device notches, rounded corners, and other hardware considerations. The design served as a bridge between abstract functional requirements (users need to send and receive messages) and concrete interface specifications that developers could implement.

The work of designing the chat screen layout represented the translation of user research and functional requirements into visual structures that would guide user attention and facilitate efficient interaction. Rather than starting with a blank canvas, the design was informed by established patterns in messaging applications that had proven effective through millions of user interactions. However, the design also needed to align with the specific context of the Professional Portfolio application, where recruiters and job seekers communicate, potentially with power imbalances and specific communication goals that differ from casual messaging. The layout design needed to accommodate these unique communication patterns while maintaining usability conventions that users already understood from other messaging applications. By creating mockups before implementation, the team could validate the design with stakeholders and make corrections relatively quickly, rather than discovering issues after substantial development effort had been invested.


=== #136 – Figma Design for Messaging Interface
*Status:* Closed | *Urgency:* 5  |  *Difficulty:* 6

This task required designing a professional, user-friendly messaging interface using Figma that would enable effective communication between recruiters and job seekers within the Professional Portfolio application. The objective extended beyond creating visually appealing screens; the design needed to establish a scalable, extensible foundation that could support future feature additions like notifications, read receipts, and file sharing without requiring major redesigns or rework. The deliverable consisted of three distinct Figma screens representing the complete messaging experience: a chat list screen displaying all recent conversations to allow users to quickly navigate to ongoing or past discussions, a one-on-one chat window where users exchange messages with a header identifying the conversation partner, scrollable message history displayed as conversation bubbles distinguishing sent versus received messages, and an input field for composing new messages, and message state variations showing delivery and read status through visual indicators (single checkmark for "sent", double checkmark for "delivered", blue double checkmark for "read").

The design explicitly rejected pre-built UI kits like Material Design or iOS human interface guidelines in favor of a custom design tailored to the unique context of recruiter-job seeker communication, recognizing that the power dynamics and communication goals in professional recruiting differ significantly from casual social messaging. Accessibility was woven throughout the design process: sufficient contrast ratios between text and backgrounds were maintained to meet WCAG standards and accommodate users with color vision deficiencies, fonts were sized large enough for comfortable reading on mobile devices, and the interface was designed to be compatible with screen readers for visually-impaired users. The layout was architected to be scalable and modular, allowing future enhancements like file upload capabilities, group chat scenarios, and dynamic typing indicators showing when another user was actively composing a message. The design included detailed specifications documenting every aspect of the visual design: specific spacing measurements (padding, margins, gaps between elements), color codes for all interface elements, icon designations and sizes, and typography specifications (font family, sizes, weights, line heights). This level of documentation served as the source of truth for developers during implementation, preventing misunderstandings about spacing, colors, or interaction timing that might deviate from the designer's intent, transforming abstract requirements like "users need to send messages" into concrete specifications like "message input field should have 16px padding, use system font at 16px size, and display send button to the right of the text input."

The task included a comprehensive testing approach to ensure quality: automated accessibility contrast checks within Figma validated that all text remained legible for users with visual impairments, responsive variations were tested across different device sizes to ensure usability from small phones to large tablets, and a short user review session with 2–3 representative test users validated that the interface was intuitive and met user expectations before handoff to development. The clickable prototype in Figma allowed stakeholders to experience the interface flow interactively, providing much richer feedback than static wireframes alone could provide. The task was successfully completed when three distinct Figma screens were delivered and properly organized, the prototype was clickable and demonstrated the complete message flow from opening a conversation to sending a message, the design adhered to brand colors and typography standards while meeting accessibility guidelines, and the layout was thoroughly documented with all necessary specifications for developer handoff. This task exemplifies the importance of thoughtful, deliberate design work in creating software that users find intuitive and enjoyable to use, establishing a visual and interaction foundation that would guide implementation and support future feature expansion.
